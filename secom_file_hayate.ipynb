{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82873ae8",
   "metadata": {},
   "source": [
    "# 2.0 DATA UNDERSTANDING STAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc768422",
   "metadata": {},
   "source": [
    "### 2.1 libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43b761",
   "metadata": {},
   "source": [
    "##### 2.1 -1 Install required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03b140fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install requests\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e242f3f",
   "metadata": {},
   "source": [
    "##### 2.1 -2 Import Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2e69a-926e-426f-b91d-1fed666dc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa3398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ead52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2f76181-4b97-4daa-822e-751e0c49f719",
   "metadata": {},
   "source": [
    "## 2.2 Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf62ae6",
   "metadata": {},
   "source": [
    "#### 2.2 -1 retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40733590-fa15-4443-bd32-643dce8cf3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['secom.data', 'secom.names', 'secom_labels.data']\n"
     ]
    }
   ],
   "source": [
    "# URL of the zipped folder\n",
    "url = \"https://archive.ics.uci.edu/static/public/179/secom.zip\"\n",
    "\n",
    "# download the zipped folder using request library\n",
    "zip_file = requests.get(url)\n",
    "\n",
    "# opening the zipped folder\n",
    "secom_files =  zipfile.ZipFile(BytesIO(secom_zip_file.content), 'r')\n",
    "\n",
    "# printing the file names inside the zip\n",
    "secom_files_names =  (zipfile.ZipFile(BytesIO(secom_zip_file.content))).namelist()\n",
    "print(secom_files_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea31b4fb-cecd-4f16-8136-ff1090e43133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the relevant files \n",
    "\n",
    "f_file = secom_files.open('secom.data')\n",
    "l_file = secom_files.open('secom_labels.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e0394",
   "metadata": {},
   "source": [
    "#### 2.2 -2 labels data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "17410d0e-7217-4e08-b8d3-8d6ab4ecc539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Labels data:  (1567, 2)\n",
      "   classifications            date_time\n",
      "0               -1  19/07/2008 11:55:00\n",
      "1               -1  19/07/2008 12:32:00\n",
      "2                1  19/07/2008 13:17:00\n",
      "3               -1  19/07/2008 14:43:00\n",
      "4               -1  19/07/2008 15:22:00\n"
     ]
    }
   ],
   "source": [
    "#Create column names and pandas dataframes for labels data\n",
    "\n",
    "l_column_names=['classifications', 'date_time'] #### create column labels\n",
    "\n",
    "labels_df = pd.read_csv(l_file, sep=r'\\s+', header=None, names= l_column_names)\n",
    "\n",
    "print(f\"Dimensions of Labels data: \", labels_df.shape)\n",
    "\n",
    "print(labels_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7714e339",
   "metadata": {},
   "source": [
    "##### 2.2 -2-1 timestamps & checking its chronological order (from oldest to newest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "113ef42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      classifications            date_time\n",
      "1562               -1  16/10/2008 15:13:00\n",
      "1563               -1  16/10/2008 20:49:00\n",
      "1564               -1  17/10/2008 05:26:00\n",
      "1565               -1  17/10/2008 06:01:00\n",
      "1566               -1  17/10/2008 06:07:00\n"
     ]
    }
   ],
   "source": [
    "print(labels_df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88ee4755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The timestamps column is in ascending (oldest to newest) order.\n"
     ]
    }
   ],
   "source": [
    "labels_df['date_time'] = pd.to_datetime(labels_df['date_time'], format='%d/%m/%Y %H:%M:%S')\n",
    "\n",
    "is_ascending = labels_df['date_time'].is_monotonic_increasing\n",
    "\n",
    "if is_ascending:\n",
    "    print(\"The timestamps column is in ascending (oldest to newest) order.\")\n",
    "else:\n",
    "    print(\"The timestamps column is not in ascending (newest to oldest) order.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea767c99-affc-4c93-8e12-85043b82b8c6",
   "metadata": {},
   "source": [
    "##### 2.2 -2-2 Date columns separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a46ab8e-d334-4664-92c4-fc558571058a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # separating date columns \n",
    "# t_df = labels_df.copy()\n",
    "# t_df[\"time\"] = t_df[\"date_time\"].dt.time\n",
    "# t_df[\"date\"] = pd.to_datetime(t_df[\"date_time\"].dt.date)\n",
    "# t_df[\"year\"] = t_df[\"date\"].dt.year\n",
    "# t_df[\"month\"] = t_df[\"date\"].dt.month\n",
    "# t_df[\"day\"] = t_df[\"date\"].dt.day\n",
    "\n",
    "# t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5768e-25eb-48ad-8cf9-3fa57ce0aafe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### checking the test result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54021934-1491-4811-bbe5-c233991c484a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of failure: 104 \n",
      "The number of pass:    1463\n"
     ]
    }
   ],
   "source": [
    "result_fail = labels_df[\"classifications\"].value_counts()[1]\n",
    "result_pass = labels_df[\"classifications\"].value_counts()[-1]\n",
    "\n",
    "print(f\"The number of failure: {result_fail} \\nThe number of pass:    {result_pass}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f00568-8024-4941-b47d-c4e674e35f71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # splitting the original data between test and training data\n",
    "\n",
    "# train_data, test_data = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "# display(len(train_data))\n",
    "# display(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bde4c451-48b9-4842-bcf3-bce06d1487de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25059856344772546"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_percentage = len(test_data)/len(train_data)\n",
    "# test_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b210cbd-ac72-468d-bdc7-1fa7d1c5f21f",
   "metadata": {},
   "source": [
    "#### 2.2 -3 SECOM.data / features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db3bdc8-8b56-4254-a2cc-d40b7f70f546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Features' data:  (1567, 591)\n",
      "---------------------------------------------------------\n",
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0    3030.93    2564.00  2187.7333  1411.1265     1.3602      100.0   \n",
      "1    3095.78    2465.14  2230.4222  1463.6606     0.8294      100.0   \n",
      "2    2932.61    2559.94  2186.4111  1698.0172     1.5102      100.0   \n",
      "3    2988.72    2479.90  2199.0333   909.7926     1.3204      100.0   \n",
      "4    3032.24    2502.87  2233.3667  1326.5200     1.5334      100.0   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  ...  feature_582  feature_583  \\\n",
      "0    97.6133     0.1242     1.5005      0.0162  ...          NaN       0.5005   \n",
      "1   102.3433     0.1247     1.4966     -0.0005  ...     208.2045       0.5019   \n",
      "2    95.4878     0.1241     1.4436      0.0041  ...      82.8602       0.4958   \n",
      "3   104.2367     0.1217     1.4882     -0.0124  ...      73.8432       0.4990   \n",
      "4   100.3967     0.1235     1.5031     -0.0031  ...          NaN       0.4800   \n",
      "\n",
      "   feature_584  feature_585  feature_586  feature_587  feature_588  \\\n",
      "0       0.0118       0.0035       2.3630          NaN          NaN   \n",
      "1       0.0223       0.0055       4.4447       0.0096       0.0201   \n",
      "2       0.0157       0.0039       3.1745       0.0584       0.0484   \n",
      "3       0.0103       0.0025       2.0544       0.0202       0.0149   \n",
      "4       0.4766       0.1045      99.3032       0.0202       0.0149   \n",
      "\n",
      "   feature_589  feature_590  feature_591  \n",
      "0          NaN          NaN          NaN  \n",
      "1       0.0060     208.2045          NaN  \n",
      "2       0.0148      82.8602          NaN  \n",
      "3       0.0044      73.8432          NaN  \n",
      "4       0.0044      73.8432          NaN  \n",
      "\n",
      "[5 rows x 591 columns]\n"
     ]
    }
   ],
   "source": [
    "f_column_names = [f\"feature_{i}\" for i in range(1, 592)]\n",
    "\n",
    "secom_features_df = pd.read_csv(f_file, sep=r'\\s+', header=None, names= f_column_names)\n",
    "print(f\"Dimensions of Features' data: \", secom_features_df.shape)\n",
    "print(\"---------------------------------------------------------\")\n",
    "print(secom_features_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767dc5a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd6c776",
   "metadata": {},
   "source": [
    "# 3.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7ca0d",
   "metadata": {},
   "source": [
    "#### 3.1 Merge the Features and Labels data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72411ae8-78e6-4f50-8ec0-7ff9fee201c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of merged data:  (1567, 593)\n",
      "   classifications           date_time  feature_1  feature_2  feature_3  \\\n",
      "0               -1 2008-07-19 11:55:00    3030.93    2564.00  2187.7333   \n",
      "1               -1 2008-07-19 12:32:00    3095.78    2465.14  2230.4222   \n",
      "2                1 2008-07-19 13:17:00    2932.61    2559.94  2186.4111   \n",
      "3               -1 2008-07-19 14:43:00    2988.72    2479.90  2199.0333   \n",
      "4               -1 2008-07-19 15:22:00    3032.24    2502.87  2233.3667   \n",
      "\n",
      "   feature_4  feature_5  feature_6  feature_7  feature_8  ...  feature_582  \\\n",
      "0  1411.1265     1.3602      100.0    97.6133     0.1242  ...          NaN   \n",
      "1  1463.6606     0.8294      100.0   102.3433     0.1247  ...     208.2045   \n",
      "2  1698.0172     1.5102      100.0    95.4878     0.1241  ...      82.8602   \n",
      "3   909.7926     1.3204      100.0   104.2367     0.1217  ...      73.8432   \n",
      "4  1326.5200     1.5334      100.0   100.3967     0.1235  ...          NaN   \n",
      "\n",
      "   feature_583  feature_584  feature_585  feature_586  feature_587  \\\n",
      "0       0.5005       0.0118       0.0035       2.3630          NaN   \n",
      "1       0.5019       0.0223       0.0055       4.4447       0.0096   \n",
      "2       0.4958       0.0157       0.0039       3.1745       0.0584   \n",
      "3       0.4990       0.0103       0.0025       2.0544       0.0202   \n",
      "4       0.4800       0.4766       0.1045      99.3032       0.0202   \n",
      "\n",
      "   feature_588  feature_589  feature_590  feature_591  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1       0.0201       0.0060     208.2045          NaN  \n",
      "2       0.0484       0.0148      82.8602          NaN  \n",
      "3       0.0149       0.0044      73.8432          NaN  \n",
      "4       0.0149       0.0044      73.8432          NaN  \n",
      "\n",
      "[5 rows x 593 columns]\n"
     ]
    }
   ],
   "source": [
    "secom_merged_df = pd.merge(labels_df, secom_features_df, left_index=True, right_index=True)\n",
    "\n",
    "print(f\"Dimensions of merged data: \", secom_merged_df.shape)\n",
    "\n",
    "print(secom_merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd280fe3-f7f1-445a-863f-502ec2cbb515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of merged data:  (1567, 593)\n",
      "   classifications           date_time  feature_1  feature_2  feature_3  \\\n",
      "0               -1 2008-07-19 11:55:00    3030.93    2564.00  2187.7333   \n",
      "1               -1 2008-07-19 12:32:00    3095.78    2465.14  2230.4222   \n",
      "2                1 2008-07-19 13:17:00    2932.61    2559.94  2186.4111   \n",
      "3               -1 2008-07-19 14:43:00    2988.72    2479.90  2199.0333   \n",
      "4               -1 2008-07-19 15:22:00    3032.24    2502.87  2233.3667   \n",
      "\n",
      "   feature_4  feature_5  feature_6  feature_7  feature_8  ...  feature_582  \\\n",
      "0  1411.1265     1.3602      100.0    97.6133     0.1242  ...          NaN   \n",
      "1  1463.6606     0.8294      100.0   102.3433     0.1247  ...     208.2045   \n",
      "2  1698.0172     1.5102      100.0    95.4878     0.1241  ...      82.8602   \n",
      "3   909.7926     1.3204      100.0   104.2367     0.1217  ...      73.8432   \n",
      "4  1326.5200     1.5334      100.0   100.3967     0.1235  ...          NaN   \n",
      "\n",
      "   feature_583  feature_584  feature_585  feature_586  feature_587  \\\n",
      "0       0.5005       0.0118       0.0035       2.3630          NaN   \n",
      "1       0.5019       0.0223       0.0055       4.4447       0.0096   \n",
      "2       0.4958       0.0157       0.0039       3.1745       0.0584   \n",
      "3       0.4990       0.0103       0.0025       2.0544       0.0202   \n",
      "4       0.4800       0.4766       0.1045      99.3032       0.0202   \n",
      "\n",
      "   feature_588  feature_589  feature_590  feature_591  \n",
      "0          NaN          NaN          NaN          NaN  \n",
      "1       0.0201       0.0060     208.2045          NaN  \n",
      "2       0.0484       0.0148      82.8602          NaN  \n",
      "3       0.0149       0.0044      73.8432          NaN  \n",
      "4       0.0149       0.0044      73.8432          NaN  \n",
      "\n",
      "[5 rows x 593 columns]\n"
     ]
    }
   ],
   "source": [
    "# merging \n",
    "\n",
    "merged_df = pd.merge(labels_df, secom_features_df, left_index=True, right_index=True)\n",
    "\n",
    "print(f\"Dimensions of merged data: \", merged_df.shape)\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44f84e",
   "metadata": {},
   "source": [
    "#### 3.2 splitting training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a99afb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed chips are: 1463 \n",
      "failed chips are: 104\n"
     ]
    }
   ],
   "source": [
    "# separating the merged df into pass and fail    #### preparing for constrained data splitting \n",
    "\n",
    "failed_chip = merged_df[merged_df[\"classifications\"] == 1]\n",
    "passed_chip = merged_df[merged_df[\"classifications\"] == -1]\n",
    "\n",
    "print(f\"passed chips are: {len(passed_chip)} \\nfailed chips are: {len(failed_chip)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a151ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed chips for training are: 83 \n",
      "failed chips for testing are:  21\n",
      "the percentage of the testing is 25.3 %\n"
     ]
    }
   ],
   "source": [
    "# splitting the failed into 25% and 75% \n",
    "\n",
    "train_data_failed, test_data_failed = train_test_split(failed_chip, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"failed chips for training are: {len(train_data_failed)} \\nfailed chips for testing are:  {len(test_data_failed)}\")\n",
    "print(f\"the percentage of the testing is {round( len(test_data_failed) / len(train_data_failed ), 4) * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3883b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passed chips for training are: 1170 \n",
      "passed chips for testing are:  293\n",
      "the percentage of the testing is 25.0 %\n"
     ]
    }
   ],
   "source": [
    "# splitting the passed into 25% and 75% \n",
    "\n",
    "train_data_passed, test_data_passed = train_test_split(passed_chip, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"passed chips for training are: {len(train_data_passed)} \\npassed chips for testing are:  {len(test_data_passed)}\")\n",
    "print(f\"the percentage of the testing is {round( len(test_data_passed) / len(train_data_passed ), 3) * 100} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9face367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253\n",
      "check: train_failed 83 + train_passed 1170 = 1253\n",
      "---------------------------------------------------------------\n",
      "314\n",
      "check: train_failed 21 + train_passed 293 = 314\n"
     ]
    }
   ],
   "source": [
    "# combining the train_failed and train_passed\n",
    "training_df = pd.concat([train_data_failed, train_data_passed])\n",
    "### counting the num of rows to check if it's properly combined \n",
    "print(len(training_df))\n",
    "print(f\"check: train_failed {len(train_data_failed)} + train_passed {len(train_data_passed)} = {len(train_data_failed) + len(train_data_passed)}\")\n",
    "\n",
    "print(\"---------------------------------------------------------------\")\n",
    "\n",
    "# combining the testing_failed and testing_passed  \n",
    "testing_df = pd.concat([test_data_failed, test_data_passed])\n",
    "### counting the num of rows to check if it's properly combined \n",
    "print(len(testing_df))\n",
    "print(f\"check: train_failed {len(test_data_failed)} + train_passed {len(test_data_passed)} = {len(test_data_failed) + len(test_data_passed)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6517286d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175abc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1637ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf6a7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a28a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
